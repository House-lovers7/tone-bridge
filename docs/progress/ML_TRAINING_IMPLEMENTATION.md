# ML Training Service å®Ÿè£…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

## ğŸ“‹ æ¦‚è¦
ToneBridge ML Training Serviceã¯ã€ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€è©•ä¾¡ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ç®¡ç†ã™ã‚‹åŒ…æ‹¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚µãƒ¼ãƒ“ã‚¹æ§‹æˆ
```
services/ml-training/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ config.py               # âœ… å®Ÿè£…æ¸ˆã¿ - ç’°å¢ƒè¨­å®šç®¡ç†
â”‚   â”œâ”€â”€ database.py             # âœ… å®Ÿè£…æ¸ˆã¿ - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç®¡ç†
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # âœ… å®Ÿè£…æ¸ˆã¿ - Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ model_trainer.py    # âš ï¸ éƒ¨åˆ†å®Ÿè£… - ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
â”‚   â”‚   â”œâ”€â”€ feedback_collector.py # âŒ æœªå®Ÿè£…
â”‚   â”‚   â”œâ”€â”€ model_evaluator.py  # âŒ æœªå®Ÿè£…
â”‚   â”‚   â”œâ”€â”€ ab_tester.py        # âŒ æœªå®Ÿè£…
â”‚   â”‚   â””â”€â”€ model_registry.py   # âŒ æœªå®Ÿè£…
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ model_utils.py      # âŒ æœªå®Ÿè£…
â”œâ”€â”€ requirements.txt            # ä¾å­˜é–¢ä¿‚å®šç¾©
â””â”€â”€ Dockerfile                  # ã‚³ãƒ³ãƒ†ãƒŠè¨­å®š
```

## ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ (2025å¹´1æœˆ)
- **HuggingFace Transformers**: 4.36.0 â†’ 4.47.1 (æ¨å¥¨ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰)
- **PEFT (LoRA)**: 0.7.0 â†’ 0.17.0 (æ¨å¥¨ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰)
- **TRL (RLHF)**: 0.7.4
- **PyTorch**: 2.1.0
- **FastAPI**: 0.104.1
- **MLflow**: 2.9.0
- **Weights & Biases**: 0.16.1

### äº’æ›æ€§ç¢ºèªæ¸ˆã¿
âœ… Transformers + PEFTçµ±åˆã¯å®Œå…¨ã‚µãƒãƒ¼ãƒˆ
âœ… LoRA/QLoRAå®Ÿè£…ã¯æœ€æ–°ç‰ˆã§å‹•ä½œç¢ºèª
âœ… 8-bit/4-bité‡å­åŒ–ã‚µãƒãƒ¼ãƒˆ (bitsandbytes)

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ

### ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹æˆ

#### training_jobs
```sql
- id: String (Primary Key)
- model_type: String (tone_adjustment, structure, etc.)
- base_model: String (gpt-4, claude-3, gemini-pro, etc.)
- dataset_id: String (Foreign Key)
- status: String (pending, running, completed, failed)
- config: JSON
- hyperparameters: JSON
- progress: Float
- metrics: JSON
- error_message: Text
- created_at: DateTime
- started_at: DateTime
- completed_at: DateTime
```

#### models
```sql
- id: String (Primary Key)
- training_job_id: String (Foreign Key)
- name: String
- version: String
- model_type: String
- base_model: String
- path: String
- metrics: JSON
- status: String (draft, staging, production, archived)
- deployed_at: DateTime
- created_at: DateTime
```

#### datasets
```sql
- id: String (Primary Key)
- name: String
- description: Text
- type: String (training, validation, test, feedback)
- file_path: String
- format: String (json, csv, parquet, jsonl)
- size_mb: Float
- num_samples: Integer
- created_at: DateTime
```

#### feedback
```sql
- id: String (Primary Key)
- user_id: String
- session_id: String
- model_id: String (Foreign Key)
- input_text: Text
- output_text: Text
- corrected_text: Text
- transformation_type: String
- rating: Integer (1-5)
- feedback_type: String
- created_at: DateTime
```

#### ab_tests
```sql
- id: String (Primary Key)
- name: String
- model_a_id: String (Foreign Key)
- model_b_id: String (Foreign Key)
- traffic_split: Float
- success_metrics: JSON
- status: String (active, paused, completed)
- winner: String
- results: JSON
- created_at: DateTime
- completed_at: DateTime
```

## ğŸš€ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

### Training Management
- `POST /train` - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–é–‹å§‹
- `GET /train/{job_id}/status` - ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
- `POST /train/{job_id}/stop` - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢

### Feedback Collection
- `POST /feedback` - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡
- `GET /feedback/stats` - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±è¨ˆ

### Model Evaluation
- `POST /evaluate/{model_id}` - ãƒ¢ãƒ‡ãƒ«è©•ä¾¡å®Ÿè¡Œ
- `POST /evaluate/compare` - ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ

### A/B Testing
- `POST /ab-test` - A/Bãƒ†ã‚¹ãƒˆä½œæˆ
- `GET /ab-test/{test_id}/results` - ãƒ†ã‚¹ãƒˆçµæœå–å¾—
- `POST /ab-test/{test_id}/stop` - ãƒ†ã‚¹ãƒˆåœæ­¢

### Model Registry
- `GET /models` - ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
- `GET /models/{model_id}` - ãƒ¢ãƒ‡ãƒ«è©³ç´°
- `POST /models/{model_id}/deploy` - ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤
- `POST /models/{model_id}/rollback` - ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

### RLHF (Reinforcement Learning from Human Feedback)
- `POST /rlhf/start` - RLHFé–‹å§‹
- `GET /rlhf/{job_id}/status` - RLHFã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

## ğŸ”‘ ç’°å¢ƒå¤‰æ•°

```env
# Database
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=tonebridge
POSTGRES_PASSWORD=password
POSTGRES_DB=tonebridge_db

# Redis
REDIS_HOST=redis
REDIS_PORT=6379

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=tonebridge-training

# Weights & Biases (Optional)
WANDB_API_KEY=your-api-key
WANDB_PROJECT=tonebridge
WANDB_ENTITY=your-entity

# Model Providers
OPENAI_API_KEY=your-key
ANTHROPIC_API_KEY=your-key
GOOGLE_API_KEY=your-key
HUGGINGFACE_TOKEN=your-token

# Training Configuration
DEFAULT_BATCH_SIZE=8
DEFAULT_LEARNING_RATE=5e-5
DEFAULT_EPOCHS=3
FP16_TRAINING=true
GRADIENT_CHECKPOINTING=true

# LoRA Configuration
LORA_R=8
LORA_ALPHA=32
LORA_DROPOUT=0.1
```

## ğŸ¯ å®Ÿè£…çŠ¶æ³

### âœ… å®Œäº†
1. **config.py**: ç’°å¢ƒè¨­å®šç®¡ç†
   - Pydantic Settingsã«ã‚ˆã‚‹å‹å®‰å…¨ãªè¨­å®š
   - ç’°å¢ƒå¤‰æ•°ã®è‡ªå‹•èª­ã¿è¾¼ã¿
   - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè‡ªå‹•ä½œæˆ

2. **database.py**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
   - SQLAlchemy Async ORM
   - AsyncPGã«ã‚ˆã‚‹é«˜é€Ÿæ¥ç¶š
   - Redisçµ±åˆ
   - ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«ç®¡ç†

3. **schemas.py**: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©
   - å®Œå…¨ãªå‹å®šç¾©
   - ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¦å‰‡
   - ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«

### ğŸš§ å®Ÿè£…ä¸­
4. **model_trainer.py**: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
   - åŸºæœ¬æ§‹é€ å®Ÿè£…æ¸ˆã¿
   - PEFT/LoRAçµ±åˆå¿…è¦
   - RLHFãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ä¸­

### âŒ æœªå®Ÿè£…
5. **feedback_collector.py**: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†
6. **model_evaluator.py**: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
7. **ab_tester.py**: A/Bãƒ†ã‚¹ãƒˆç®¡ç†
8. **model_registry.py**: ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª
9. **model_utils.py**: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°

## ğŸ’¡ å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

### LoRAå®Ÿè£…
```python
from peft import LoraConfig, get_peft_model, TaskType

# LoRAè¨­å®š
lora_config = LoraConfig(
    r=8,  # ãƒ©ãƒ³ã‚¯
    lora_alpha=32,
    lora_dropout=0.1,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    task_type=TaskType.CAUSAL_LM
)

# ãƒ¢ãƒ‡ãƒ«ã«LoRAã‚’é©ç”¨
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()  # å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: 0.19%
```

### RLHFå®Ÿè£…
```python
from trl import PPOTrainer, PPOConfig

ppo_config = PPOConfig(
    batch_size=128,
    mini_batch_size=4,
    learning_rate=1e-5,
    kl_penalty=0.1
)

ppo_trainer = PPOTrainer(
    config=ppo_config,
    model=model,
    ref_model=ref_model,
    tokenizer=tokenizer
)
```

## ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **æ®‹ã‚Šã®ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…**
   - FeedbackCollector
   - ModelEvaluator
   - ABTester
   - ModelRegistry

2. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**
   - Alembicã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
   - åˆæœŸãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ

3. **ãƒ†ã‚¹ãƒˆå®Ÿè£…**
   - ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
   - çµ±åˆãƒ†ã‚¹ãƒˆ
   - è² è·ãƒ†ã‚¹ãƒˆ

4. **ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™**
   - Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æœ€é©åŒ–
   - Kubernetesè¨­å®š
   - CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

## ğŸ› æ—¢çŸ¥ã®å•é¡Œ

1. **GPU ãƒ¡ãƒ¢ãƒªç®¡ç†**
   - å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®OOMå¯¾ç­–å¿…è¦
   - gradient_checkpointingæ¨å¥¨
   - 8-bit/4-bité‡å­åŒ–æ¤œè¨

2. **ä¸¦åˆ—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°**
   - DeepSpeedçµ±åˆæœªå®Œäº†
   - Accelerateè¨­å®šå¿…è¦

3. **ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°**
   - DVCçµ±åˆæ¤œè¨
   - S3/GCSå¯¾å¿œå¿…è¦

## ğŸ“š å‚è€ƒè³‡æ–™

- [HuggingFace PEFT Documentation](https://huggingface.co/docs/peft)
- [TRL Documentation](https://huggingface.co/docs/trl)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)

---

*Last Updated: 2025-01-15*
*Version: 0.3.0*
*Status: Development*